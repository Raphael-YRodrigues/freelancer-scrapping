{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Upwork Jobs \u2014 Load & Explore\n", "\n", "Use either a **clean CSV** produced by your parser or a **saved HTML** from Upwork search results.\n", "\n", "**Instructions**:\n", "1. Set `CSV_PATH` if you already have `upwork_clean.csv` (columns like `job_id, title, ...`).\n", "2. Or set `HTML_PATH` to a saved Upwork HTML page and run the parser cells to generate the DataFrame.\n", "3. Run the EDA cells to inspect rows, skills, price ranges, and simple charts.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "import pandas as pd\n", "import re\n", "\n", "# ---- Configure one or both paths ----\n", "# If you already have a CSV from the parser, point to it here:\n", "CSV_PATH = Path('upwork_clean.csv')  # change to your CSV path\n", "\n", "# If you saved raw Upwork HTML and want to parse inside this notebook, set this:\n", "HTML_PATH = Path('test.html')       # change to your HTML path or leave None\n", "\n", "pd.set_option('display.max_colwidth', 180)\n", "pd.set_option('display.max_rows', 50)\n", "pd.set_option('display.width', 160)\n", "print('Paths configured:', {'csv': str(CSV_PATH), 'html': str(HTML_PATH)})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Optional: Parser for Upwork HTML\n", "If `selectolax` is not installed, this cell will install it. Then it defines parsing helpers to read a saved Upwork search HTML and produce a DataFrame identical to the CSV schema."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "try:\n", "    from selectolax.parser import HTMLParser\n", "except Exception:\n", "    # When running locally, this will install. It won't run in environments without internet access.\n", "    %pip install selectolax --quiet\n", "    from selectolax.parser import HTMLParser\n", "\n", "from urllib.parse import urljoin\n", "from datetime import datetime\n", "\n", "BASE = 'https://www.upwork.com'\n", "MONEY = re.compile(r\"([$\\u20ac\\u00a3])\\s*([\\d.,]+)(?:\\s*[-\u2013]\\s*([$\\u20ac\\u00a3])?\\s*([\\d.,]+))?\")\n", "JOB_ID = re.compile(r\"_~([0-9a-z]+)\", re.I)\n", "HIGHLIGHT_NOISE = re.compile(r\"\\bspan[-\\s]?class[-\\s]?highlight\\b|</?span[^>]*>\", re.I)\n", "WS = re.compile(r\"\\s+\")\n", "\n", "def clean_text(s: str) -> str:\n", "    if not s:\n", "        return ''\n", "    s = HIGHLIGHT_NOISE.sub(' ', s)\n", "    s = WS.sub(' ', s).strip()\n", "    return s\n", "\n", "def currency_code(sym: str) -> str:\n", "    return {'$':'USD', '\u20ac':'EUR', '\u00a3':'GBP'}.get(sym, '')\n", "\n", "def parse_price(article):\n", "    price_type = ''\n", "    price_min = price_max = ''\n", "    currency = ''\n", "\n", "    label = article.css_first(\"li[data-test='job-type-label'] strong\")\n", "    if label:\n", "        t = label.text(strip=True).lower()\n", "        if 'hour' in t:\n", "            price_type = 'hourly'\n", "        if 'fixed' in t or 'budget' in t:\n", "            price_type = 'fixed'\n", "\n", "    li = article.css_first(\"li[data-test='is-fixed-price'], li[data-test='is-hourly']\")\n", "    txt = li.text(separator=' ', strip=True) if li else article.text(separator=' ', strip=True)\n", "    m = MONEY.search(txt)\n", "    if m:\n", "        sym1, a1, sym2, a2 = m.groups()\n", "        currency = currency_code(sym1 or sym2 or '')\n", "        def norm(x):\n", "            return float(x.replace(',', ''))\n", "        if a1 and a2:\n", "            price_min, price_max = str(norm(a1)), str(norm(a2))\n", "        elif a1:\n", "            price_min = price_max = str(norm(a1))\n", "\n", "    return price_type, currency, price_min, price_max\n", "\n", "def parse_posted(article):\n", "    time_el = article.css_first(\"time[datetime]\")\n", "    posted_at = time_el.attributes.get('datetime') if time_el else ''\n", "    txt_all = clean_text(article.text(separator=' ', strip=True))\n", "    m = re.search(r\"posted\\s+[^|]+ago\", txt_all, re.I)\n", "    posted_text = m.group(0) if m else ''\n", "    return posted_at, posted_text\n", "\n", "FRAMEWORK_DICT = [\n", "    'Python','Scrapy','Selenium','BeautifulSoup','Requests','Pandas','NumPy',\n", "    'Power BI','Tableau','Google Maps API','LinkedIn','GitHub','JavaScript','Node.js',\n", "    'Playwright','Excel','Regex','API','ETL','Airflow'\n", "]\n", "\n", "def extract_frameworks(text_blob, skills_list):\n", "    blob = f\"{text_blob} {' '.join(skills_list)}\".lower()\n", "    found, seen, out = [], set(), []\n", "    for fw in FRAMEWORK_DICT:\n", "        if fw.lower() in blob:\n", "            found.append(fw)\n", "    for x in found:\n", "        if x not in seen:\n", "            out.append(x); seen.add(x)\n", "    return ', '.join(out)\n", "\n", "def parse_article(a):\n", "    a_title = a.css_first(\"a[data-test='job-tile-title-link']\")\n", "    title = clean_text(a_title.text(strip=True) if a_title else '')\n", "    url = urljoin(BASE, a_title.attributes.get('href', '')) if a_title else ''\n", "    url = url.split('?', 1)[0]\n", "    job_id = ''\n", "    if url:\n", "        m = JOB_ID.search(url)\n", "        if m:\n", "            job_id = m.group(1)\n", "\n", "    p = a.css_first('p.text-body-sm') or a.css_first('.air3-line-clamp p, .air3-line-clamp')\n", "    desc = clean_text(p.text(separator=' ', strip=True) if p else '')\n", "\n", "    skills = [clean_text(s.text(strip=True)) for s in a.css(\"div.air3-token-container button.air3-token span\") if clean_text(s.text(strip=True))]\n", "\n", "    price_type, currency, price_min, price_max = parse_price(a)\n", "    level_el = a.css_first(\"li[data-test='experience-level'] strong\")\n", "    level = level_el.text(strip=True) if level_el else ''\n", "    posted_at, posted_text = parse_posted(a)\n", "\n", "    # naive role inference\n", "    t = f\"{title} {desc}\".lower()\n", "    s = ' '.join(skills).lower()\n", "    role = ''\n", "    if 'power bi' in t or 'power bi' in s:\n", "        role = 'Power BI Developer'\n", "    elif 'data analyst' in t or 'data analysis' in t:\n", "        role = 'Data Analyst'\n", "    elif 'web scraping' in t or 'scraping' in t:\n", "        role = 'Web Scraping Specialist'\n", "    elif 'python' in t or 'python' in s:\n", "        role = 'Python Developer'\n", "    elif 'etl' in t or 'etl' in s:\n", "        role = 'ETL Engineer'\n", "\n", "    frameworks = extract_frameworks(f\"{title} {desc}\", skills)\n", "\n", "    return {\n", "        'platform': 'upwork',\n", "        'job_id': job_id,\n", "        'title': title,\n", "        'description': desc,\n", "        'role': role,\n", "        'level': level,\n", "        'skills': ', '.join(skills),\n", "        'frameworks': frameworks,\n", "        'price_type': price_type,\n", "        'currency': currency,\n", "        'price_min': price_min,\n", "        'price_max': price_max,\n", "        'posted_at': posted_at,\n", "        'posted_text': posted_text,\n", "        'url': url,\n", "    }\n", "\n", "def parse_upwork_html_to_df(html_path: Path) -> pd.DataFrame:\n", "    html = html_path.read_text(encoding='utf-8', errors='ignore')\n", "    dom = HTMLParser(html)\n", "    arts = dom.css('article.job-tile')\n", "    rows = [parse_article(a) for a in arts]\n", "    return pd.DataFrame(rows)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load data\n", "Choose one of the two blocks below: **load CSV** or **parse HTML**."]}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": ["parameters"]}, "outputs": [], "source": ["df = None\n", "if CSV_PATH and CSV_PATH.exists():\n", "    df = pd.read_csv(CSV_PATH)\n", "    print(f\"Loaded CSV with {len(df)} rows from {CSV_PATH}\")\n", "elif HTML_PATH and HTML_PATH.exists():\n", "    df = parse_upwork_html_to_df(HTML_PATH)\n", "    print(f\"Parsed HTML with {len(df)} rows from {HTML_PATH}\")\n", "else:\n", "    raise FileNotFoundError('Neither CSV_PATH nor HTML_PATH exists. Set one of them to a valid file.')\n", "\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Basic overview"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Shape:', df.shape)\n", "print('Columns:', list(df.columns))\n", "display_cols = [c for c in ['platform','job_id','title','role','level','price_type','currency','price_min','price_max','posted_at','url'] if c in df.columns]\n", "df[display_cols].head(20)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Skills analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def split_skills(s):\n", "    if pd.isna(s):\n", "        return []\n", "    return [x.strip() for x in str(s).split(',') if x.strip()]\n", "\n", "skills_series = df.get('skills')\n", "if skills_series is not None:\n", "    exploded = df.assign(skill=df['skills'].fillna('').apply(split_skills)).explode('skill')\n", "    top_skills = exploded[exploded['skill']!='']['skill'].value_counts().head(20)\n", "    print(top_skills)\n", "else:\n", "    print('No skills column present.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Plot: Top 15 skills"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "skills_series = df.get('skills')\n", "if skills_series is not None:\n", "    exploded = df.assign(skill=df['skills'].fillna('').apply(split_skills)).explode('skill')\n", "    vc = exploded[exploded['skill']!='']['skill'].value_counts().head(15)\n", "    plt.figure()\n", "    vc.sort_values().plot(kind='barh')\n", "    plt.title('Top 15 Skills')\n", "    plt.xlabel('Count')\n", "    plt.ylabel('Skill')\n", "    plt.tight_layout()\n", "    plt.show()\n", "else:\n", "    print('No skills column present for plotting.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Price summary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cols = [c for c in ['price_type','currency','price_min','price_max'] if c in df.columns]\n", "if cols:\n", "    display(df[cols].head())\n", "    if 'price_min' in df.columns:\n", "        with pd.option_context('display.float_format', '{:,.2f}'.format):\n", "            print('price_min describe:\\n', pd.to_numeric(df['price_min'], errors='coerce').dropna().describe())\n", "    if 'price_max' in df.columns:\n", "        with pd.option_context('display.float_format', '{:,.2f}'.format):\n", "            print('price_max describe:\\n', pd.to_numeric(df['price_max'], errors='coerce').dropna().describe())\n", "else:\n", "    print('No price columns present.')"]}]}